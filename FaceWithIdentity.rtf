{\rtf1\ansi\ansicpg1252\cocoartf2580
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red191\green100\blue38;\red32\green32\blue32;\red153\green168\blue186;
\red109\green109\blue109;\red254\green187\blue91;\red86\green132\blue173;\red88\green118\blue71;}
{\*\expandedcolortbl;;\csgenericrgb\c74902\c39216\c14902;\csgenericrgb\c12549\c12549\c12549;\csgenericrgb\c60000\c65882\c72941;
\csgenericrgb\c42745\c42745\c42745;\csgenericrgb\c99608\c73333\c35686;\csgenericrgb\c33725\c51765\c67843;\csgenericrgb\c34510\c46275\c27843;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs26 \cf2 \cb3 import \cf4 face_recognition\
\cf2 import \cf4 os\
\cf2 import \cf4 csv\
\cf2 import \cf4 cv2\
\cf2 import \cf4 numpy \cf2 as \cf4 np\
\cf2 import \cf4 math\
\
\
\cf5 # Helper\
\cf2 def \cf6 face_confidence\cf4 (face_distance\cf2 , \cf4 face_match_threshold=\cf7 0.6\cf4 ):\
    range = (\cf7 1.0 \cf4 - face_match_threshold)\
    linear_val = (\cf7 1.0 \cf4 - face_distance) / (range * \cf7 2.0\cf4 )\
\
    \cf2 if \cf4 face_distance > face_match_threshold:\
        \cf2 return \cf4 str(round(linear_val * \cf7 100\cf2 , \cf7 2\cf4 )) + \cf8 '%'\
    \cf2 else\cf4 :\
        value = (linear_val + ((\cf7 1.0 \cf4 - linear_val) * math.pow((linear_val - \cf7 0.5\cf4 ) * \cf7 2\cf2 , \cf7 0.2\cf4 ))) * \cf7 100\
        \cf2 return \cf4 str(round(value\cf2 , \cf7 2\cf4 )) + \cf8 '%'\
\
\
\cf2 class \cf4 FaceRecognition:\
    face_locations = []\
    face_encodings = []\
    face_names = []\
    face_ages = []\
    face_genders = []\
    known_face_encodings = []\
    known_face_names = []\
    known_face_ages = []\
    known_face_genders = []\
    process_current_frame = \cf2 True\
\
    def \cf4 __init__(self):\
        self.encode_faces()\
\
    \cf2 def \cf6 encode_faces\cf4 (self):\
        \cf2 with \cf4 open(\cf8 '/Users/anggaarindra/Downloads/MachineLearning/FaceRecognition/dataset.csv'\cf2 , \cf8 'r'\cf4 ) \cf2 as \cf4 file:\
            csv_reader = csv.DictReader(file\cf2 , \cf4 delimiter=\cf8 ';'\cf4 )\
            \cf2 for \cf4 row \cf2 in \cf4 csv_reader:\
                name = row[\cf8 'nama'\cf4 ]\
                image_path = row[\cf8 'path'\cf4 ]\
                age = row[\cf8 'umur'\cf4 ]\
                gender = row[\cf8 'jenis_kelamin'\cf4 ]\
\
                face_image = face_recognition.load_image_file(image_path)\
                face_encoding = face_recognition.face_encodings(face_image)[\cf7 0\cf4 ]\
\
                self.known_face_encodings.append(face_encoding)\
                self.known_face_names.append(name)\
                self.known_face_ages.append(age)\
                self.known_face_genders.append(gender)\
                print(self.known_face_names)\
\
\
    \cf2 def \cf6 run_recognition\cf4 (self):\
        video_capture = cv2.VideoCapture(\cf7 0\cf4 )\
\
        \cf2 if not \cf4 video_capture.isOpened():\
            sys.exit(\cf8 'Video source not found...'\cf4 )\
\
        \cf2 while True\cf4 :\
            ret\cf2 , \cf4 frame = video_capture.read()\
\
            \cf5 # Only process every other frame of video to save time\
            \cf2 if \cf4 self.process_current_frame:\
                \cf5 # Resize frame of video to 1/4 size for faster face recognition processing\
                \cf4 small_frame = cv2.resize(frame\cf2 , \cf4 (\cf7 0\cf2 , \cf7 0\cf4 )\cf2 , \cf4 fx=\cf7 0.25\cf2 , \cf4 fy=\cf7 0.25\cf4 )\
\
                \cf5 # Convert the image from BGR color (which OpenCV uses) to RGB color (which face_recognition uses)\
                \cf4 rgb_small_frame = cv2.cvtColor(small_frame\cf2 , \cf4 cv2.COLOR_BGR2RGB)\
\
                \cf5 # Find all the faces and face encodings in the current frame of video\
                \cf4 self.face_locations = face_recognition.face_locations(rgb_small_frame)\
                self.face_encodings = face_recognition.face_encodings(rgb_small_frame)\
\
                self.face_names = []\
                self.face_ages = []\
                self.face_genders = []\
                \cf2 for \cf4 face_encoding \cf2 in \cf4 self.face_encodings:\
                    \cf5 # See if the face is a match for the known face(s)\
                    \cf4 matches = face_recognition.compare_faces(self.known_face_encodings\cf2 , \cf4 face_encoding)\
                    name = \cf8 "Unknown"\
                    \cf4 age = \cf8 "Unknown"\
                    \cf4 gender = \cf8 "Unknown"\
                    \cf4 confidence = \cf8 '???'\
\
                    \cf5 # Calculate the shortest distance to face\
                    \cf4 face_distances = face_recognition.face_distance(self.known_face_encodings\cf2 , \cf4 face_encoding)\
\
                    best_match_index = np.argmin(face_distances)\
                    \cf2 if \cf4 matches[best_match_index]:\
                        name = self.known_face_names[best_match_index]\
                        age = self.known_face_ages[best_match_index]\
                        gender = self.known_face_genders[best_match_index]\
                        confidence = face_confidence(face_distances[best_match_index])\
\
                    self.face_names.append(\cf8 f'\cf2 \{\cf4 name\cf2 \}\cf8  (\cf2 \{\cf4 confidence\cf2 \}\cf8 )'\cf4 )\
                    self.face_ages.append(age)\
                    self.face_genders.append(gender)\
\
            self.process_current_frame = \cf2 not \cf4 self.process_current_frame\
\
            \cf5 # Display the results\
            \cf2 for \cf4 (top\cf2 , \cf4 right\cf2 , \cf4 bottom\cf2 , \cf4 left)\cf2 , \cf4 name\cf2 , \cf4 age\cf2 , \cf4 gender \cf2 in \cf4 zip(self.face_locations\cf2 , \cf4 self.face_names\cf2 ,\
                                                                     \cf4 self.face_ages\cf2 , \cf4 self.face_genders):\
                \cf5 # Scale back up face locations since the frame we detected in was scaled to 1/4 size\
                \cf4 top *= \cf7 4\
                \cf4 right *= \cf7 4\
                \cf4 bottom *= \cf7 4\
                \cf4 left *= \cf7 4\
\
                \cf5 # Create the frame with the name, age, and gender\
                \cf4 cv2.rectangle(frame\cf2 , \cf4 (left\cf2 , \cf4 top)\cf2 , \cf4 (right\cf2 , \cf4 bottom)\cf2 , \cf4 (\cf7 0\cf2 , \cf7 0\cf2 , \cf7 255\cf4 )\cf2 , \cf7 2\cf4 )\
                cv2.rectangle(frame\cf2 , \cf4 (left\cf2 , \cf4 bottom - \cf7 35\cf4 )\cf2 , \cf4 (right\cf2 , \cf4 bottom)\cf2 , \cf4 (\cf7 0\cf2 , \cf7 0\cf2 , \cf7 255\cf4 )\cf2 , \cf4 cv2.FILLED)\
                cv2.putText(frame\cf2 , \cf4 name\cf2 , \cf4 (left + \cf7 6\cf2 , \cf4 bottom - \cf7 50\cf4 )\cf2 , \cf4 cv2.FONT_HERSHEY_DUPLEX\cf2 , \cf7 0.8\cf2 , \cf4 (\cf7 255\cf2 , \cf7 255\cf2 , \cf7 255\cf4 )\cf2 , \cf7 1\cf4 )\
                cv2.putText(frame\cf2 , \cf8 f'Age: \cf2 \{\cf4 age\cf2 \}\cf8 '\cf2 , \cf4 (left + \cf7 6\cf2 , \cf4 bottom - \cf7 30\cf4 )\cf2 , \cf4 cv2.FONT_HERSHEY_DUPLEX\cf2 , \cf7 0.8\cf2 ,\
                            \cf4 (\cf7 255\cf2 , \cf7 255\cf2 , \cf7 255\cf4 )\cf2 , \cf7 1\cf4 )\
                cv2.putText(frame\cf2 , \cf8 f'Gender: \cf2 \{\cf4 gender\cf2 \}\cf8 '\cf2 , \cf4 (left + \cf7 6\cf2 , \cf4 bottom - \cf7 10\cf4 )\cf2 , \cf4 cv2.FONT_HERSHEY_DUPLEX\cf2 , \cf7 0.8\cf2 ,\
                            \cf4 (\cf7 255\cf2 , \cf7 255\cf2 , \cf7 255\cf4 )\cf2 , \cf7 1\cf4 )\
\
            \cf5 # Display the resulting image\
            \cf4 cv2.imshow(\cf8 'Face Recognition'\cf2 , \cf4 frame)\
\
            \cf5 # Hit 'q' on the keyboard to quit!\
            \cf2 if \cf4 cv2.waitKey(\cf7 1\cf4 ) == ord(\cf8 'q'\cf4 ):\
                \cf2 break\
\
        \cf5 # Release handle to the webcam\
        \cf4 video_capture.release()\
        cv2.destroyAllWindows()\
\
\
\cf2 if \cf4 __name__ == \cf8 '__main__'\cf4 :\
    fr = FaceRecognition()\
    fr.run_recognition()\
\
}